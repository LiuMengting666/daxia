##### 代码解析

[TOC]



##### 训练样本处理

Compose常用于图像的转换，把多个步骤整合到一起的包。

```python
transform = T.Compose([
    T.ToTensor(), 
])
```

###### 将类别标签数字化

class Coding(Dataset):
    
```python
class Coding(Dataset):
def __init__(self, root, transform=None):
    self.root = root
    self.paths = os.listdir(root)
    self.transforms = transform   
    
def one_hot(self, label):
    bp = torch.Tensor([])
    for i in range(len(label)):
        num = ord(label[i])-48
        if num>9:
            num -= 7
            if num>35:
                num -= 6         
        a = torch.zeros(1, 62)
        a[:,num] = 1
        bp = torch.cat((bp,a),dim=1)
    return bp
    
def __getitem__(self, index):
    image_path = self.paths[index]    
    label = list(image_path)[:-4]
    label = self.one_hot(label).reshape(310)

    pil_image = Image.open(self.root+image_path)
    if self.transforms:
        data = self.transforms(pil_image)
    else:
        image_array = np.asarray(pil_image)
        data = torch.from_numpy(image_array)
    return data, label

def __len__(self):
    return len(self.paths)
```
在函数```Codeimg```中主要是`onehot`,这个函数先将类别标签转换成ASCII码，但是因为ASCII码是不连续的，所以又将其连续起来

```参数```

​	盛放类别标签的数组[0,1,2....."a","b"......"z"]

```输出```

​	调整好的类别标签

```小细节``

​	torch.cat是将两个张量（tensor）拼接在一起，cat是concatnate的意思，即拼接，联系在一起。

​	bp是事先构造好的tensor，b是每一次都构造了一个1*62的零tensor，然后只把第a列置为1，最后构造出来是一个斜对角线上是1的2维tensor

​	<font color='red'>当时不太懂为什么维度是1</font>

附上两个例子

```python
x = torch.randn(2, 3)
x
tensor([[ 0.6580, -1.0969, -0.4614],
        [-0.1034, -0.5790,  0.1497]])
>>> torch.cat((x, x, x), 0)
tensor([[ 0.6580, -1.0969, -0.4614],
        [-0.1034, -0.5790,  0.1497],
        [ 0.6580, -1.0969, -0.4614],
        [-0.1034, -0.5790,  0.1497],
        [ 0.6580, -1.0969, -0.4614],
        [-0.1034, -0.5790,  0.1497]])
>>> torch.cat((x, x, x), 1)
tensor([[ 0.6580, -1.0969, -0.4614,  0.6580, -1.0969, -0.4614,  0.6580,
         -1.0969, -0.4614],
        [-0.1034, -0.5790,  0.1497, -0.1034, -0.5790,  0.1497, -0.1034,
         -0.5790,  0.1497]])
```

###### `getitem`

​	通过index可以知道图片的名称，self.parhs是初始化定义的，是一个数组，label获取的是前5个字符，正好是类别标签，然后将前面的根目录和图片的名称拼接，就形成了完整的目录，然后就要把image类型的转换为tensor类型的，先看看有没有容器，有容器直接转换，没有容器的话，就先转换为numpy再转换为tensor类型的，最后返回转换为tensor类型的数据和这个数据的类别标签

`len`

​	返回的是这个目录下需要处理的文件的个数，以便于后续的操作，

##### 残差块

接着创建一个类，这个类主要用于残差块的构建，首先我们定义一个我们自己的类ResidualBlock,然后它继承了nn.Module这个类, 我们可以转到nn.Module这个父类，发现里面会有很多方法，其中就有__init__(self)和forward(self) 这两个函数，这样就很明白了，这就是重写嘛，但是如果想要一些自己定义的一些外面参数，那么我们就需要在__init__(self)中添加一些外部参数，然后变成这样def __init__(self, inchannel, outchannel, stride=1)，但是仍然需要继承nn.Module.__init__(self)的相关方法啊，所以就要使用super(ResidualBlock, self).__init__()， 如果不使用super而显示调用父类的初始化函数，就会出现多次初始化的问题。
	**init**()相当于是我们的名词，然后forward()是我们的动作，就比如定义一个网络,**init**()定义我们的网络有哪些层，但是没有定义网络是如何定义的，而forward()定义网络是如何连接起来的。

​	就像所说的那样，在`init`中定义了

>nn.Conv2d(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True))
>参数：
>  in_channel:　输入数据的通道数，例RGB图片通道数为3；
>  out_channel: 输出数据的通道数，这个根据模型调整；
>  kennel_size: 卷积核大小，可以是int，或tuple；kennel_size=2,意味着卷积大小2， kennel_size=（2,3），意味着卷积在第一维度大小为2，在第二维度大小为3；
>  stride：步长，默认为1，与kennel_size类似，stride=2,意味在所有维度步长为2， stride=（2,3），意味着在第一维度步长为2，意味着在第二维度步长为3；
>  padding：　1填充
>
>

计算公式为 d = (d - kennel_size + 2 * padding) / stride + 1

>nn.BatchNorm2d(out_channel),        
>
> #BatchNorm2d最常用于卷积网络中(防止梯度消失或爆炸)，设置的参数就是卷积的输出通道数

在定义完成卷积后，接下来就是`shorcut`了

​	对于开始的Resnet-18结构来说，shortcut存在二种不同的类型，一种是经过网络之后输出和输入尺寸是一样的，还有一种输出和输入的**维度不匹配**，这个时候我们通过Conv + BN的方法将输入的尺寸变成输出尺寸！所以要有两手准备！！



```python
class ResidualBlock(nn.Module):
    def __init__(self, inchannel, outchannel, stride=1):
        super(ResidualBlock, self).__init__()
        self.left = nn.Sequential(
            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),
            nn.BatchNorm2d(outchannel),
            nn.ReLU(),
            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),
            nn.BatchNorm2d(outchannel)
        )
        self.shortcut = nn.Sequential()
        if stride != 1 or inchannel != outchannel:
            self.shortcut = nn.Sequential(
                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(outchannel)
            )
    def forward(self, x):
        out = self.left(x)
        out += self.shortcut(x)
        out = F.relu(out)
        return out
```



##### 残差网络的构建

接下来就是`ResNet`了，

首先就是要继承原本的ResNet，定义了输入通道数为64，这个是自己规定的，可以进行改变，接着就是使用了一个容器，规定了进行卷积的各项参数，然后伴随着BatchNorm2d防止梯度消失或爆炸，接着定义三层神经网络，用于训练，传一个步长进去，根据数据的大小，步长可能为1，也可能为2



其实最后发现这两个函数一个是残差块，一个是残差网络

>“残差在数理统计中是指实际观察值与估计值（拟合值）之间的差。”“如果回归模型正确的话， 我们可以将残差看作误差的观测值。”
>
>　　更准确地，假设想要找一个 x，使得 f(x)=b，给定一个 x 的估计值 x0，残差（residual）就是 b−f(x0)，同时，误差就是 x−x0
>
>　　即使 x 不知道，我们仍然可以计算残差，只是不能计算误差罢了。

残差网络

>残差网络通过加入 shortcut connections，变得更加容易被优化。包含一个 shortcut connection 的几层网络被称为一个残差块

最后呢就是将残差块放入残差网络调用函数，截止到目前为止，网络就构建成功 了

```python

class ResNet(nn.Module):
    def __init__(self, ResidualBlock, num_classes=310):
        super(ResNet, self).__init__()
        self.inchannel = 64
        self.conv1 = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(),
        )
        self.layer1 = self.make_layer(ResidualBlock, 64,  2, stride=1)
        self.layer2 = self.make_layer(ResidualBlock, 128, 2, stride=2)
        self.layer3 = self.make_layer(ResidualBlock, 256, 2, stride=2)
        self.fc = nn.Linear(4608, num_classes)

    def make_layer(self, block, channels, num_blocks, stride):
        strides = [stride] + [1] * (num_blocks - 1)
        layers = []
        for stride in strides:
            layers.append(block(self.inchannel, channels, stride))
            self.inchannel = channels
        return nn.Sequential(*layers)

    def forward(self, x):
        out = self.conv1(x)
        out = self.layer1(out)
        out = self.layer2(out)
        out = self.layer3(out)
        out = F.avg_pool2d(out, 4)
        out = out.view(out.size(0), -1)
        out = self.fc(out)
        return out
```



接下来就是数据传入进行训练了

```python
data = Codeimg('train/train/', transform)
dataloader = DataLoader(data, batch_size=32, shuffle=True, drop_last=False)
img, label = data[0]
```

然后调用函数构建网络

```python
cnn = ResNet18()
```

计算损失和优化器

```python
loss_fn = nn.MultiLabelSoftMarginLoss()
optimizer = torch.optim.Adam(cnn.parameters())
```

##### 训练，寻找参数

开始训练,寻找最好的循环次数，先前向传播，计算损失，导数清零，反向传播

```python
for i in range(6):  
    for j,(img,labels) in enumerate(dataloader):
        out = cnn(img)
        loss = loss_fn(out, labels)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        if j % 100 == 0:
            print('i=%d j=%d Loss: %.5f' %(i,j,loss.item()))
```

为了保存参数，写进文件文件中

```python
torch.save(cnn.state_dict(),'parameter.pt')
```

得到参数后需要开始进行预测,先读取预测的图片

```python
data = UnCoding('test/test/', transform)
cnn = ResNet18()
cnn.load_state_dict(torch.load('parameter2.pt'))
```

##### 进行预测

j将data的数据一个一个送进残差网络,用softmax预测，得到概率最大的下标为类别标签

```python

for i in range(len(data)):
    imgs, labels = data[i]
    imgs = torch.Tensor(imgs).reshape(1,3,30,150)
    single_result = cnn(imgs)
    single_result = single_result.view(-1, 62)
    single_result = nn.functional.softmax(single_result, dim=1)
    single_result = torch.argmax(single_result, dim=1)
    out = uncode(single_result)
    result[labels] = out
```

##### 转换类别标签

最后将预测的数据类别标签转换回来

```python
def uncode(code):
    result = list()
    for i in range(len(code)):
        if code[i]<10:
            result.append(chr(code[i]+48))
        elif 10<=code[i]<36:
            result.append(chr(code[i]+55))
        else: 
            result.append(chr(code[i]+61))
    return result
```

##### 写进文档

最后将数据连同index按照要求的提交格式写进文件中去

```python
index = list()
labels = list()
for i in range(len(result)):
    index.append(i)
    labels.append(''.join(result[i]))
np.savetxt('sample.csv',labels, fmt='%s')
```

