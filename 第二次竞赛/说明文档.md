#### 代码解释

1. 先对数据集进行数据的处理，我尝试过用平均值和方差这两种方法，发现用平均值比较高一些，所以最后用平均值填充的

   ```python	
   train_df = pd.read_csv('train.csv',header=None)
   test_df = pd.read_csv('test.csv',header=None)
   a = np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0])
   for j in range(14):
       for i in range(7194):
           if(train_df.iloc[i][j]=="?"):
               train_df.iloc[i,j]=NaN
       train_df.iloc[:,j]=train_df.iloc[:,j].dropna().astype(int)
       a[j] = train_df.loc[:,j].dropna().mean()
       train_df.iloc[:,j] = train_df.iloc[:,j].fillna(a[j])
       for k in range(1798):
           if(j!=13 and test_df.iloc[k][j]=="?"):
               test_df.iloc[k,j]=NaN
               print(j)
       if(j!=13):
           test_df.iloc[:,j] = test_df.iloc[:,j].fillna(a[j])
   f = open(r'C:\Users\10104\Desktop\\mean_train.csv','w')
   f2 = open(r'C:\Users\10104\Desktop\\mean_test.csv','w')
   train_df.to_csv(r'C:\Users\10104\Desktop\\mean_train.csv', sep=',',header=None,index=None)
   test_df.to_csv(r'C:\Users\10104\Desktop\\mean_test.csv', sep=',',header=None,index=None)
   f.close()
   f2.close()
   ```

   我用a这个数据来盛放每一列的平均值，然后一列一列的去循环，将？改为NAN，在用方法将NAN代替为平均值，最后将处理好的数据写进文件中去~

2. 开始读数据

   ```python
   def init_data():
       data = np.loadtxt(r'C:\Users\10104\Desktop\\mean_train.csv',delimiter=',')
       data2 = np.loadtxt(r'C:\Users\10104\Desktop\\mean_test.csv',delimiter=',')
       dataMatIn,classLabels = np.split(data, (13,), axis=1)#将数据和类别标号
       classLabels=classLabels.ravel()
       return dataMatIn,classLabels,data2
   ```

   定义了一个函数，用来读取处理完成的数据，并且将特征向量和标签进行分开

3. 采用交叉验证的方法寻找最好的k和最好的列的参数

   ```python
   X_train,X_test,y_train,y_test=model_selection.train_test_split(X_train,y_train,test_size=0.20,random_state=5)
   ```

   <font color='green'>小插曲：其实一开始还想为了保证数据的准确性，把有不确定的样本都删掉，最后发现训练出来的测试集正确率很低，还想过将问号多的某一列删掉，发现也不是很高，最后就开始我暴虐的方法</font>

4. 我先进行了主观判断，我感觉对收入的影响最大的是教育程度和工作年限，所以我先对这两列进行的参数0.5~3的循环，在这个循环内部是还有一个大循环，是对选择的这个参数进行k值的选择，找到在这个参数下，那个k会使训练出来的正确率最高

   <img src="C:\Users\10104\AppData\Roaming\Typora\typora-user-images\1574146973645.png" alt="1574146973645" style="zoom: 67%;" />

结果就是非常的慢，我的小电脑快不行聊，但他还是坚持着，我是从第四列开始的，先看看教育程度选择那个参数，选择那个k比较好，然后再在第四列的基础上看第一列怎样处理，就这样一直处理下去，知道处理之后比没处理要差

```python
xun = [i/10.0 for i in range(5,21)]
for i in xun:
    X_train[:,7] = daye

    X_train[:,7] = X_train[:,7]*i
    accuracy = []
    for n_neighbors in range(70,100):                 
        for weights in ['uniform']:
            temp_wrong = []
            for train_index,test_index in kfold.split(X_train):
                clf = KNeighborsClassifier(n_neighbors)
                clf.fit(X_train[train_index],y_train[train_index])
                pred = clf.predict(X_train[test_index])
                temp_wrong.append(1-accuracy_score(y_train[test_index],pred))
            accuracy.append(temp_wrong)
    accuracy = np.array(accuracy)
    mean = np.mean(accuracy,axis = 1)
    
    std = np.std(accuracy,axis = 1)
# =============================================================================
#     plt.figure(figsize = (50,5))
#     plot_data = np.array([mean,mean+std,mean-std]).T
#     plt.plot(plot_data,marker='.')
#     plt.grid(True)
# =============================================================================
    # =============================================================================
    b = mean
    min_acc = np.min(b)
    # =============================================================================
    index_min = 70 + np.argmin(b)
    print(i,index_min,1-min_acc)
```

![1574147192386](C:\Users\10104\AppData\Roaming\Typora\typora-user-images\1574147192386.png)会出来类似这种的形式，第一个表示参数，第二个是在这个参数的情况下的最好的k，第三个是最好的k对应的正确率

然后就这样选定参数

就这样一直循环，我发现下面这一种组合会使结果比较高

![1574147251585](C:\Users\10104\AppData\Roaming\Typora\typora-user-images\1574147251585.png)

然后对测试集的列做同样的操作

![1574147280433](C:\Users\10104\AppData\Roaming\Typora\typora-user-images\1574147280433.png)

最后对结果写进一个二维数组，写进文件

```python
clf = neighbors.KNeighborsClassifier(90, weights=weights)
clf.fit(X_train,y_train)        
y_test_pred = clf.predict(data2)    
print(y_test_pred.shape)

pre = [[] for i in range(1798)]
count = 1
for i in y_test_pred:  
     pre[count-1].append(count)
     pre[count-1].append(i)
     count+=1
    
f = open(r'C:\Users\10104\Desktop\\la.csv','w')
np.savetxt(r'C:\Users\10104\Desktop\\la.csv',pre,delimiter=',')
f.close()
```

#### 总结

这一段时间有点忙，没有太多的时间去尝试更好的方法，因为我上面的方法训练一个参数基本都需要20分钟，很遗憾没有尝试不同的先后顺序对结果的影响，也没有尝试对数据进行升维的方法，但是因为期末考试和下一个竞赛的胁迫，不得已结束这次竞赛，不够也在夹缝中学会了很多，比如自己亲手对数据进行了处理，比如我写出了这么一个复杂的循环自己去寻找最好的参数，再比如，正确率一直上不去，心态由暴躁到平稳，下一个加油！！！！！

